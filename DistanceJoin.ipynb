{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DistanceJoin.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNb7rdia3x5Z4b7qdREy8yi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spros1/DistanceJoin/blob/main/DistanceJoin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###First we need to install everything needed in order to run Python & Apache Spark in Colab\n"
      ],
      "metadata": {
        "id": "IxOtCtC2AF7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install Java8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "VzUF5N4eAFBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download spark3.2.1\n",
        "!wget -q https://ftp.cc.uoc.gr/mirrors/apache/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz "
      ],
      "metadata": {
        "id": "svHzX8UeAVum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip it\n",
        "!tar xvf spark-3.2.1-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "R0abKQaoAV8l",
        "outputId": "1e6d53c3-ffc6-44ca-d3a5-b1d419f28355",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark-3.2.1-bin-hadoop2.7/\n",
            "spark-3.2.1-bin-hadoop2.7/LICENSE\n",
            "spark-3.2.1-bin-hadoop2.7/NOTICE\n",
            "spark-3.2.1-bin-hadoop2.7/R/\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/INDEX\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/Meta/\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/NAMESPACE\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/R/\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/R/SparkR\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/help/\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/help/AnIndex\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/help/paths.rds\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/html/\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/html/00Index.html\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/html/R.css\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/profile/\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/profile/general.R\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/profile/shell.R\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/tests/\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/tests/testthat/\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/worker/\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/SparkR/worker/worker.R\n",
            "spark-3.2.1-bin-hadoop2.7/R/lib/sparkr.zip\n",
            "spark-3.2.1-bin-hadoop2.7/README.md\n",
            "spark-3.2.1-bin-hadoop2.7/RELEASE\n",
            "spark-3.2.1-bin-hadoop2.7/bin/\n",
            "spark-3.2.1-bin-hadoop2.7/bin/beeline\n",
            "spark-3.2.1-bin-hadoop2.7/bin/beeline.cmd\n",
            "spark-3.2.1-bin-hadoop2.7/bin/docker-image-tool.sh\n",
            "spark-3.2.1-bin-hadoop2.7/bin/find-spark-home\n",
            "spark-3.2.1-bin-hadoop2.7/bin/find-spark-home.cmd\n",
            "spark-3.2.1-bin-hadoop2.7/bin/load-spark-env.cmd\n",
            "spark-3.2.1-bin-hadoop2.7/bin/load-spark-env.sh\n",
            "spark-3.2.1-bin-hadoop2.7/bin/pyspark\n",
            "spark-3.2.1-bin-hadoop2.7/bin/pyspark.cmd\n",
            "spark-3.2.1-bin-hadoop2.7/bin/pyspark2.cmd\n",
            "spark-3.2.1-bin-hadoop2.7/bin/run-example\n",
            "spark-3.2.1-bin-hadoop2.7/bin/run-example.cmd\n",
            "spark-3.2.1-bin-hadoop2.7/bin/spark-class\n",
            "spark-3.2.1-bin-hadoop2.7/bin/spark-class.cmd\n",
            "spark-3.2.1-bin-hadoop2.7/bin/spark-class2.cmd\n",
            "spark-3.2.1-bin-hadoop2.7/bin/spark-shell\n",
            "spark-3.2.1-bin-hadoop2.7/bin/spark-shell.cmd\n",
            "spark-3.2.1-bin-hadoop2.7/bin/spark-shell2.cmd\n",
            "spark-3.2.1-bin-hadoop2.7/bin/spark-sql\n",
            "spark-3.2.1-bin-hadoop2.7/bin/spark-sql.cmd\n",
            "spark-3.2.1-bin-hadoop2.7/bin/spark-sql2.cmd\n",
            "spark-3.2.1-bin-hadoop2.7/bin/spark-submit\n",
            "spark-3.2.1-bin-hadoop2.7/bin/spark-submit.cmd\n",
            "spark-3.2.1-bin-hadoop2.7/bin/spark-submit2.cmd\n",
            "spark-3.2.1-bin-hadoop2.7/bin/sparkR\n",
            "spark-3.2.1-bin-hadoop2.7/bin/sparkR.cmd\n",
            "spark-3.2.1-bin-hadoop2.7/bin/sparkR2.cmd\n",
            "spark-3.2.1-bin-hadoop2.7/conf/\n",
            "spark-3.2.1-bin-hadoop2.7/conf/fairscheduler.xml.template\n",
            "spark-3.2.1-bin-hadoop2.7/conf/log4j.properties.template\n",
            "spark-3.2.1-bin-hadoop2.7/conf/metrics.properties.template\n",
            "spark-3.2.1-bin-hadoop2.7/conf/spark-defaults.conf.template\n",
            "spark-3.2.1-bin-hadoop2.7/conf/spark-env.sh.template\n",
            "spark-3.2.1-bin-hadoop2.7/conf/workers.template\n",
            "spark-3.2.1-bin-hadoop2.7/data/\n",
            "spark-3.2.1-bin-hadoop2.7/data/graphx/\n",
            "spark-3.2.1-bin-hadoop2.7/data/graphx/followers.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/graphx/users.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/als/\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/als/test.data\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/gmm_data.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/license.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/origin/\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/origin/kittens/\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/origin/license.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/origin/multi-channel/\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/partitioned/\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/iris_libsvm.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/kmeans_data.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/pagerank_data.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/pic_data.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/ridge-data/\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/sample_lda_data.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/sample_movielens_data.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/sample_svm_data.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.2.1-bin-hadoop2.7/data/streaming/\n",
            "spark-3.2.1-bin-hadoop2.7/data/streaming/AFINN-111.txt\n",
            "spark-3.2.1-bin-hadoop2.7/examples/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/jars/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/examples/jars/spark-examples_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/als.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/kmeans.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/logistic_regression.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/als_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/pagerank.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/pi.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/sort.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/sql/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/sql/arrow.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/sql/basic.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/sql/datasource.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/sql/hive.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/sql/streaming/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_sessionization.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/status_api_demo.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/streaming/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/transitive_closure.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/python/wordcount.py\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/data-manipulation.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/dataframe.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/als.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/fmClassifier.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/fmRegressor.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/fpm.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/gbt.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/glm.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/kstest.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/lda.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/logit.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/ml.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/mlp.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/survreg.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/streaming/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/META-INF/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/META-INF/services/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/dir1/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/employees.json\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/full_user.avsc\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/kv1.txt\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/people.csv\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/people.json\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/people.txt\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/user.avsc\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/users.avro\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/users.orc\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/resources/users.parquet\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/extensions/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scripts/\n",
            "spark-3.2.1-bin-hadoop2.7/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.2.1-bin-hadoop2.7/jars/\n",
            "spark-3.2.1-bin-hadoop2.7/jars/HikariCP-2.5.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/JLargeArrays-1.5.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/JTransforms-3.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/RoaringBitmap-0.9.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/ST4-4.0.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/activation-1.1.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/aircompressor-0.21.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/algebra_2.12-2.0.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/annotations-17.0.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/antlr4-runtime-4.8.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/aopalliance-1.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/apacheds-i18n-2.0.0-M15.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/apacheds-kerberos-codec-2.0.0-M15.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/api-asn1-api-1.0.0-M20.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/api-util-1.0.0-M20.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/arpack-2.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/arrow-format-2.0.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/arrow-memory-core-2.0.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/arrow-memory-netty-2.0.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/arrow-vector-2.0.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/automaton-1.11-8.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/avro-1.10.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/avro-ipc-1.10.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/avro-mapred-1.10.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/blas-2.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/breeze-macros_2.12-1.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/breeze_2.12-1.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/cats-kernel_2.12-2.1.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/chill-java-0.10.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/chill_2.12-0.10.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-beanutils-1.9.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-cli-1.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-codec-1.15.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-collections-3.2.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-compiler-3.0.16.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-compress-1.21.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-configuration-1.6.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-crypto-1.1.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-dbcp-1.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-digester-1.8.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-httpclient-3.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-io-2.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-lang-2.6.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-lang3-3.12.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-logging-1.1.3.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-math3-3.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-net-3.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-pool-1.5.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/commons-text-1.6.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/compress-lzf-1.0.3.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/core-1.1.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/curator-client-2.7.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/curator-framework-2.7.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/curator-recipes-2.7.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/derby-10.14.2.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/flatbuffers-java-1.9.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/generex-1.0.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/gson-2.2.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/guava-14.0.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/guice-3.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/guice-servlet-3.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hadoop-annotations-2.7.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hadoop-auth-2.7.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hadoop-client-2.7.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hadoop-common-2.7.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hadoop-hdfs-2.7.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hadoop-mapreduce-client-app-2.7.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hadoop-mapreduce-client-common-2.7.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hadoop-mapreduce-client-core-2.7.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hadoop-mapreduce-client-jobclient-2.7.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hadoop-mapreduce-client-shuffle-2.7.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hadoop-yarn-api-2.7.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hadoop-yarn-client-2.7.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hadoop-yarn-common-2.7.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hadoop-yarn-server-common-2.7.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hadoop-yarn-server-web-proxy-2.7.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hive-beeline-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hive-cli-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hive-common-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hive-exec-2.3.9-core.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hive-jdbc-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hive-llap-common-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hive-metastore-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hive-serde-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hive-service-rpc-3.1.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hive-shims-0.23-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hive-shims-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hive-shims-common-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hive-shims-scheduler-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hive-storage-api-2.7.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hive-vector-code-gen-2.3.9.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hk2-api-2.6.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/htrace-core-3.1.0-incubating.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/httpclient-4.5.13.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/httpcore-4.4.14.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/ivy-2.5.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jackson-annotations-2.12.3.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jackson-core-2.12.3.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jackson-databind-2.12.3.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jackson-dataformat-yaml-2.12.3.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jackson-datatype-jsr310-2.11.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jackson-jaxrs-1.9.13.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jackson-module-scala_2.12-2.12.3.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jackson-xc-1.9.13.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jakarta.servlet-api-4.0.3.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/janino-3.0.16.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/javassist-3.25.0-GA.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/javax.inject-1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/javolution-5.5.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jaxb-api-2.2.11.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jcl-over-slf4j-1.7.30.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jdo-api-3.0.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jersey-client-2.34.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jersey-common-2.34.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jersey-container-servlet-2.34.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jersey-container-servlet-core-2.34.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jersey-hk2-2.34.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jersey-server-2.34.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jetty-6.1.26.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jetty-sslengine-6.1.26.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jetty-util-6.1.26.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jline-2.14.6.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/joda-time-2.10.10.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jodd-core-3.5.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jpam-1.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/json-1.8.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/json4s-ast_2.12-3.7.0-M11.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/json4s-core_2.12-3.7.0-M11.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/json4s-jackson_2.12-3.7.0-M11.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/json4s-scalap_2.12-3.7.0-M11.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jsp-api-2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jsr305-3.0.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jta-1.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/jul-to-slf4j-1.7.30.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-client-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-admissionregistration-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-apiextensions-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-apps-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-autoscaling-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-batch-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-certificates-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-common-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-coordination-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-core-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-discovery-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-events-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-extensions-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-flowcontrol-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-metrics-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-networking-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-node-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-policy-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-rbac-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-scheduling-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/kubernetes-model-storageclass-5.4.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/lapack-2.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/libfb303-0.9.3.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/libthrift-0.12.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/log4j-1.2.17.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/logging-interceptor-3.12.12.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/lz4-java-1.7.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/macro-compat_2.12-1.1.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/mesos-1.4.0-shaded-protobuf.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/metrics-core-4.2.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/metrics-graphite-4.2.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/metrics-jmx-4.2.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/metrics-json-4.2.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/metrics-jvm-4.2.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/minlog-1.3.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/netty-all-4.1.68.Final.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/objenesis-2.6.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/okhttp-3.12.12.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/okio-1.14.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/opencsv-2.3.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/orc-core-1.6.12.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/orc-mapreduce-1.6.12.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/orc-shims-1.6.12.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/oro-2.0.8.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/paranamer-2.8.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/parquet-column-1.12.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/parquet-common-1.12.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/parquet-encoding-1.12.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/parquet-format-structures-1.12.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/parquet-hadoop-1.12.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/parquet-jackson-1.12.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/protobuf-java-2.5.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/py4j-0.10.9.3.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/pyrolite-4.30.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/rocksdbjni-6.20.3.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/scala-collection-compat_2.12-2.1.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/scala-compiler-2.12.15.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/scala-library-2.12.15.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/scala-parser-combinators_2.12-1.1.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/scala-reflect-2.12.15.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/scala-xml_2.12-1.2.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/shapeless_2.12-2.3.3.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/shims-0.9.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/slf4j-api-1.7.30.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/slf4j-log4j12-1.7.30.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/snakeyaml-1.27.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/snappy-java-1.1.8.4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-catalyst_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-core_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-graphx_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-hive-thriftserver_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-hive_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-kubernetes_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-kvstore_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-launcher_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-mesos_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-mllib-local_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-mllib_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-network-common_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-network-shuffle_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-repl_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-sketch_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-sql_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-streaming_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-tags_2.12-3.2.1-tests.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-tags_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spark-yarn_2.12-3.2.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spire-macros_2.12-0.17.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spire-platform_2.12-0.17.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spire-util_2.12-0.17.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/spire_2.12-0.17.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/stax-api-1.0.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/stream-2.9.6.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/super-csv-2.2.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/threeten-extra-1.5.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/tink-1.6.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/transaction-api-1.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/univocity-parsers-2.9.1.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/velocity-1.5.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/xbean-asm9-shaded-4.20.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/xercesImpl-2.12.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/xml-apis-1.4.01.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/xmlenc-0.52.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/xz-1.8.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/zookeeper-3.6.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/zookeeper-jute-3.6.2.jar\n",
            "spark-3.2.1-bin-hadoop2.7/jars/zstd-jni-1.5.0-4.jar\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/dockerfiles/\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/decom.sh\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/tests/\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/tests/autoscale.py\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/tests/decommissioning.py\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/tests/decommissioning_cleanup.py\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/tests/py_container_checks.py\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/tests/pyfiles.py\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/tests/python_executable_check.py\n",
            "spark-3.2.1-bin-hadoop2.7/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-CC0.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-antlr.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-arpack.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-automaton.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-blas.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-datatables.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-f2j.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-janino.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-javassist.html\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-javolution.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-jline.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-jodd.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-join.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-jquery.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-kryo.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-machinist.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-minlog.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-modernizr.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-mustache.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-netlib.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-paranamer.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-protobuf.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-py4j.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-re2j.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-respond.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-scala.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-scopt.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-slf4j.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-spire.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.2.1-bin-hadoop2.7/licenses/LICENSE-zstd.txt\n",
            "spark-3.2.1-bin-hadoop2.7/python/\n",
            "spark-3.2.1-bin-hadoop2.7/python/.coveragerc\n",
            "spark-3.2.1-bin-hadoop2.7/python/.gitignore\n",
            "spark-3.2.1-bin-hadoop2.7/python/MANIFEST.in\n",
            "spark-3.2.1-bin-hadoop2.7/python/README.md\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/Makefile\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/make.bat\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/make2.bat\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/_static/\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/_static/copybutton.js\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/_static/css/\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/_static/css/pyspark.css\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/_templates/\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/_templates/autosummary/\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/_templates/autosummary/class.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/conf.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/development/\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/development/contributing.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/development/debugging.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/development/index.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/development/setting_ide.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/development/testing.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/getting_started/\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/getting_started/index.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/getting_started/install.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/getting_started/quickstart_df.ipynb\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/getting_started/quickstart_ps.ipynb\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/index.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/migration_guide/\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/migration_guide/index.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/migration_guide/koalas_to_pyspark.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_1.0_1.2_to_1.3.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_1.4_to_1.5.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.2_to_2.3.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.3.0_to_2.3.1_above.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.3_to_2.4.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.4_to_3.0.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_3.1_to_3.2.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/index.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.ml.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.mllib.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/extensions.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/frame.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/general_functions.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/groupby.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/index.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/indexing.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/io.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/ml.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/series.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.pandas/window.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.resource.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.sql.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.ss.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/reference/pyspark.streaming.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/arrow_pandas.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/index.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/best_practices.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/faq.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/from_to_dbms.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/index.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/options.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/pandas_pyspark.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/transform_apply.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/typehints.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/pandas_on_spark/types.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/python_packaging.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/sql/\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/sql/arrow_pandas.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/docs/source/user_guide/sql/index.rst\n",
            "spark-3.2.1-bin-hadoop2.7/python/lib/\n",
            "spark-3.2.1-bin-hadoop2.7/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.2.1-bin-hadoop2.7/python/lib/py4j-0.10.9.3-src.zip\n",
            "spark-3.2.1-bin-hadoop2.7/python/lib/pyspark.zip\n",
            "spark-3.2.1-bin-hadoop2.7/python/mypy.ini\n",
            "spark-3.2.1-bin-hadoop2.7/python/pylintrc\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/__init__.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/_globals.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/_typing.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/accumulators.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/accumulators.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/broadcast.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/broadcast.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/cloudpickle/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/cloudpickle/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/cloudpickle/cloudpickle.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/cloudpickle/compat.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/conf.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/conf.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/context.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/context.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/daemon.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/files.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/files.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/find_spark_home.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/install.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/java_gateway.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/join.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/_typing.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/base.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/base.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/classification.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/classification.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/clustering.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/clustering.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/common.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/common.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/evaluation.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/evaluation.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/feature.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/feature.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/fpm.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/fpm.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/functions.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/functions.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/image.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/image.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/linalg/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/param/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/param/__init__.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/param/shared.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/param/shared.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/pipeline.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/pipeline.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/recommendation.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/recommendation.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/regression.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/regression.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/stat.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/stat.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tests/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tests/test_tuning.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tests/test_util.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tree.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tree.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tuning.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/tuning.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/util.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/util.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/wrapper.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/_typing.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/classification.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/classification.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/clustering.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/clustering.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/common.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/common.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/evaluation.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/evaluation.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/feature.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/feature.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/fpm.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/fpm.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/linalg/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/random.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/random.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/recommendation.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/recommendation.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/regression.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/regression.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/stat/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/stat/test.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/stat/test.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/tests/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/tree.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/tree.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/util.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/mllib/util.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/_typing.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/accessors.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/base.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/categorical.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/config.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/base.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/binary_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/boolean_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/categorical_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/complex_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/date_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/datetime_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/null_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/num_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/string_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/data_type_ops/udt_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/datetimes.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/exceptions.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/extensions.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/frame.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/generic.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/groupby.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/indexes/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/indexes/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/indexes/base.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/indexes/category.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/indexes/datetimes.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/indexes/multi.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/indexes/numeric.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/indexing.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/internal.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/missing/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/missing/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/missing/common.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/missing/frame.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/missing/groupby.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/missing/indexes.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/missing/series.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/missing/window.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/ml.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/mlflow.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/namespace.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/numpy_compat.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/plot/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/plot/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/plot/core.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/plot/matplotlib.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/plot/plotly.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/series.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/spark/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/spark/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/spark/accessors.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/spark/functions.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/spark/utils.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/sql_processor.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/strings.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_base.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_binary_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_boolean_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_categorical_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_complex_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_date_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_datetime_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_null_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_num_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_string_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/test_udt_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/data_type_ops/testing_utils.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/indexes/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/indexes/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/indexes/test_base.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/indexes/test_category.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/indexes/test_datetime.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/plot/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/plot/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/plot/test_frame_plot.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/plot/test_frame_plot_matplotlib.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/plot/test_series_plot.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/plot/test_series_plot_matplotlib.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/plot/test_series_plot_plotly.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_categorical.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_config.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_csv.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_dataframe.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_dataframe_conversion.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_dataframe_spark_io.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_default_index.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_expanding.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_extension.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_frame_spark.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_groupby.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_indexing.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_indexops_spark.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_internal.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_namespace.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_numpy_compat.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_ops_on_diff_frames.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_expanding.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_rolling.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_repr.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_reshape.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_rolling.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_series.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_series_conversion.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_series_datetime.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_series_string.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_spark_functions.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_sql.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_stats.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_typedef.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_utils.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/tests/test_window.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/typedef/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/typedef/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/typedef/string_typehints.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/typedef/typehints.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/usage_logging/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/usage_logging/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/usage_logging/usage_logger.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/utils.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/pandas/window.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/profiler.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/profiler.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/py.typed\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/rdd.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/rdd.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/rddsampler.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/resource/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/resource/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/resource/information.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/resource/information.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/resource/profile.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/resource/profile.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/resource/requests.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/resource/requests.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/resource/tests/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/resource/tests/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/resource/tests/test_resources.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/resultiterable.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/resultiterable.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/serializers.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/shell.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/shuffle.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/__init__.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/_typing.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/avro/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/avro/functions.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/avro/functions.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/catalog.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/catalog.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/column.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/column.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/conf.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/conf.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/context.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/context.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/dataframe.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/functions.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/functions.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/group.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/group.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/functions.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/functions.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/group_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/group_ops.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/map_ops.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/map_ops.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/serializers.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/typehints.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/types.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/pandas/utils.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/readwriter.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/readwriter.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/session.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/session.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/streaming.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/streaming.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_grouped_map.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_map.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_window.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_streaming.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/types.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/types.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/udf.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/udf.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/utils.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/window.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/window.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/statcounter.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/statcounter.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/status.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/status.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/storagelevel.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/storagelevel.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/context.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/context.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/dstream.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/dstream.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/kinesis.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/kinesis.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/listener.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/listener.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/tests/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/streaming/util.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/taskcontext.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/taskcontext.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/testing/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/testing/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/testing/mllibutils.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/testing/mlutils.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/testing/pandasutils.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/testing/sqlutils.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/testing/streamingutils.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/testing/utils.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/__init__.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_conf.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_context.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_daemon.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_install_spark.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_join.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_profiler.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_rdd.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_serializers.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_util.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/tests/test_worker.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/traceback_utils.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/util.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/util.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/version.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/version.pyi\n",
            "spark-3.2.1-bin-hadoop2.7/python/pyspark/worker.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/run-tests\n",
            "spark-3.2.1-bin-hadoop2.7/python/run-tests-with-coverage\n",
            "spark-3.2.1-bin-hadoop2.7/python/run-tests.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/setup.cfg\n",
            "spark-3.2.1-bin-hadoop2.7/python/setup.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_coverage/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_coverage/conf/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_coverage/coverage_daemon.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_coverage/sitecustomize.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/hello/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/hello/hello.txt\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/hello/sub_hello/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/ages.csv\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_common_metadata\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_metadata\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/people.json\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/people1.json\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/people_array.json\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/streaming/\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/sql/text-test.txt\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/userlib-0.1.zip\n",
            "spark-3.2.1-bin-hadoop2.7/python/test_support/userlibrary.py\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/decommission-slave.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/decommission-worker.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/slaves.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/spark-config.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/spark-daemon.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/spark-daemons.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/start-all.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/start-history-server.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/start-master.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/start-slave.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/start-slaves.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/start-thriftserver.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/start-worker.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/start-workers.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/stop-all.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/stop-history-server.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/stop-master.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/stop-slave.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/stop-slaves.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/stop-thriftserver.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/stop-worker.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/stop-workers.sh\n",
            "spark-3.2.1-bin-hadoop2.7/sbin/workers.sh\n",
            "spark-3.2.1-bin-hadoop2.7/yarn/\n",
            "spark-3.2.1-bin-hadoop2.7/yarn/spark-3.2.1-yarn-shuffle.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install findspark \n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "jw2mHjOKAWFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "1S3dyF7BAWMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A test in order to check that all are ok"
      ],
      "metadata": {
        "id": "VzSgZmRqAhlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()                                               # make pyspark importable as a regular library\n",
        "from pyspark.sql import SparkSession                           # create Spark session\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "# Test spark\n",
        "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj4UQd2vAWTn",
        "outputId": "6536c6a6-4789-43b7-f0c9-ef9d389ee3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now lets start :\n",
        "For two sets given A and B ( with values (ID,X,Y) ) : <br>\n",
        "Find the pairs (a,b), where a in Α and b in Β, \n",
        "to wich it applies : d(a,b) ≤ c, where c parameter given from the user "
      ],
      "metadata": {
        "id": "cEXxpskFv5gj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First we are going to make a routine in order to produce two csv files with the number of records that the user will give\n"
      ],
      "metadata": {
        "id": "_Kjaub_FB_3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports that are going to be used for the population for our two datasets \n",
        "import random\n",
        "import time\n",
        "from random import sample\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "gEW8kdy04GRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_generated_points( gen_num, csv_name):\n",
        "  \n",
        "  x = random.sample(range(1, gen_num+1), gen_num)\n",
        "  y = random.sample(range(1, gen_num+1), gen_num)\n",
        "\n",
        "  fin_data = list(zip(x,y))\n",
        " \n",
        "# generate csv\n",
        "  with open(csv_name, \"a\") as f:\n",
        "    f.truncate(0)\n",
        "    coords = [map(str, tupl) for tupl in fin_data]\n",
        "    writer = csv.writer(f, delimiter=',')\n",
        "\n",
        "    for line in coords:\n",
        "      writer.writerow(line)\n",
        "\n",
        "# plot it also that \n",
        "  plt.scatter(x, y)\n",
        "  plt.show()\n",
        "\n",
        "  return fin_data"
      ],
      "metadata": {
        "id": "LrtRZbitBu_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now the user must give the max number of points for the two datasets"
      ],
      "metadata": {
        "id": "VfK76d7MKVLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inpCSV_total_points = 0\n",
        "try:\n",
        "  inpCSV_total_points = int(input(\"Enter the max value for csv with inp points : \"))\n",
        "except ValueError:\n",
        "    print(\"This is not a number\")   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-yVh9RYKJqU",
        "outputId": "14a70cc6-1b15-4c36-d9ad-e75cbb77e9c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the max value for csv with inp points : 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainCSV_total_points = 0\n",
        "try:\n",
        "  trainCSV_total_points = int(input(\"Enter the max value for csv with train points : \"))\n",
        "except ValueError:\n",
        "    print(\"This is not a number\")   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XcWZSqmKeKL",
        "outputId": "94456705-92c4-4b45-e65a-2515ecc8341b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the max value for csv with train points : 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the input dataset\n",
        "inpPoints = get_generated_points(inpCSV_total_points , 'InputCSV.csv')\n",
        "print(inpPoints)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "trainPoints = get_generated_points(trainCSV_total_points , 'TrainCSV.csv')\n",
        "print(trainPoints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "3hgD3j0TBqNz",
        "outputId": "28220c3e-e72e-47a5-dbed-f19e906038f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(40, 68), (64, 43), (55, 94), (43, 26), (67, 73), (87, 45), (25, 8), (20, 63), (8, 83), (24, 81), (83, 54), (13, 78), (29, 93), (26, 28), (33, 92), (17, 91), (10, 29), (48, 24), (44, 85), (88, 23), (16, 34), (70, 77), (69, 86), (6, 56), (68, 88), (56, 21), (45, 36), (75, 6), (15, 69), (31, 74), (2, 65), (51, 48), (50, 97), (3, 44), (23, 7), (11, 99), (7, 42), (71, 76), (47, 31), (32, 87), (81, 98), (59, 75), (65, 33), (91, 82), (96, 53), (38, 71), (1, 22), (79, 61), (93, 96), (89, 13), (54, 9), (35, 57), (52, 14), (57, 37), (60, 27), (63, 67), (77, 79), (98, 3), (42, 90), (58, 70), (85, 72), (72, 50), (84, 51), (5, 17), (21, 100), (49, 80), (14, 64), (82, 40), (41, 39), (100, 89), (39, 59), (74, 62), (34, 10), (61, 58), (76, 20), (12, 95), (92, 84), (4, 47), (53, 5), (97, 19), (46, 25), (18, 66), (90, 15), (28, 55), (30, 16), (27, 38), (73, 60), (95, 12), (62, 18), (19, 1), (86, 2), (66, 4), (99, 30), (94, 52), (37, 41), (36, 32), (80, 46), (22, 11), (9, 49), (78, 35)]\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(16, 18), (42, 10), (19, 7), (14, 25), (32, 27), (39, 44), (30, 47), (21, 35), (17, 48), (5, 50), (3, 3), (48, 17), (25, 43), (45, 42), (4, 14), (23, 46), (22, 5), (49, 6), (6, 23), (24, 20), (2, 49), (12, 39), (8, 29), (31, 36), (15, 28), (38, 16), (28, 45), (26, 4), (29, 15), (33, 41), (36, 24), (37, 2), (44, 12), (18, 26), (20, 31), (35, 11), (27, 32), (46, 38), (40, 22), (9, 34), (50, 8), (41, 9), (34, 33), (47, 37), (10, 1), (13, 40), (11, 13), (1, 30), (7, 19), (43, 21)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read from the two csvs the data\n",
        "(from the two we create or other , it is the same just change the name of input file)\n"
      ],
      "metadata": {
        "id": "Grz8kKWyroOA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBle1FUSkXMP"
      },
      "outputs": [],
      "source": [
        "# importing the required module\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as f\n",
        "from pyspark.sql.functions import lit,col,concat\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# give the path of input and train file to read \n",
        "inpFile   = \"InputCSV.csv\" \n",
        "trainFile = \"TrainCSV.csv\""
      ],
      "metadata": {
        "id": "KkYTgCC8QJmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark session\n",
        "t0 = int(round(time.time() * 1000))"
      ],
      "metadata": {
        "id": "HwvyuECSzli_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"CSV\").master(\"local\").getOrCreate()             # Creates a session on a local master\n"
      ],
      "metadata": {
        "id": "_eHHJq9Vl1SL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = int(round(time.time() * 1000))\n",
        "\n",
        "print(\"Session initialized in {} ms\".format(t1 - t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmIge-J3zzZL",
        "outputId": "5522c36a-5ca7-4c0c-f28a-8c328d87da4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session initialized in 8487 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_inp   = spark.read.csv(inferSchema=True, path=inpFile).toDF(\"inpX\"  ,\"inpY\"  )     # Reads input CSV file with no header, in a dataframe\n",
        "df_train = spark.read.csv(inferSchema=True, path=trainFile).toDF(\"trainX\",\"trainY\")   # Reads train CSV file with no header, in a dataframe"
      ],
      "metadata": {
        "id": "4ovFQfXdzzdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = int(round(time.time() * 1000))\n",
        "print(\"Initial dataframe built in {} ms\".format(t2 - t1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWp0CCC-0FqN",
        "outputId": "4e9156e5-ae5a-4b8f-fc5c-4fb4e5ae803e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial dataframe built in 8726 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"*** Right after ingestion ***\")\n",
        "\n",
        "df_inp.show(5)\n",
        "print(\"We have {} input records.\".format(df_inp.count()))\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "df_train.show(5)\n",
        "print(\"We have {} train records.\".format(df_train.count()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOtFXlFJM75F",
        "outputId": "cd61555a-a60a-46b7-ab44-71b0064911ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Right after ingestion ***\n",
            "+----+----+\n",
            "|inpX|inpY|\n",
            "+----+----+\n",
            "|  40|  68|\n",
            "|  64|  43|\n",
            "|  55|  94|\n",
            "|  43|  26|\n",
            "|  67|  73|\n",
            "+----+----+\n",
            "only showing top 5 rows\n",
            "\n",
            "We have 100 input records.\n",
            "\n",
            "\n",
            "+------+------+\n",
            "|trainX|trainY|\n",
            "+------+------+\n",
            "|    16|    18|\n",
            "|    42|    10|\n",
            "|    19|     7|\n",
            "|    14|    25|\n",
            "|    32|    27|\n",
            "+------+------+\n",
            "only showing top 5 rows\n",
            "\n",
            "We have 50 train records.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the schema to standard output (stdout) by using printSchema().\n",
        "df_inp.printSchema()\n",
        "df_train.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqoXl9_nM_Gt",
        "outputId": "e5e00540-4ee3-4f8f-e7d2-a97ec774f240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- inpX: integer (nullable = true)\n",
            " |-- inpY: integer (nullable = true)\n",
            "\n",
            "root\n",
            " |-- trainX: integer (nullable = true)\n",
            " |-- trainY: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find min & max x y for both datasets, and for total (limits of grid)\n"
      ],
      "metadata": {
        "id": "MvJ7EbhIH_Tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dfMaxMin(dtf,columnNamex,columnNamey ): \n",
        "\n",
        "  dtf_X_Min = dtf.agg({columnNamex: 'min'}).collect()[0][0]\n",
        "  dtf_X_Max = dtf.agg({columnNamex: 'max'}).collect()[0][0]\n",
        "  dtf_Y_Min = dtf.agg({columnNamey: 'min'}).collect()[0][0]\n",
        "  dtf_Y_Max = dtf.agg({columnNamey: 'max'}).collect()[0][0]\n",
        "\n",
        "  return dtf_X_Min, dtf_X_Max, dtf_Y_Min, dtf_Y_Max"
      ],
      "metadata": {
        "id": "f3pLzO7eIO4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call function to find min max per dataframe\n",
        "minX_inp,maxX_inp,minY_inp,maxY_inp = dfMaxMin(df_inp, 'inpX', 'inpY')\n",
        "print( minX_inp,maxX_inp, '-', minY_inp,maxY_inp )\n",
        "\n",
        "minX_trn,maxX_trn, minY_trn,maxY_trn  = dfMaxMin(df_train, 'trainX', 'trainY')\n",
        "print( minX_trn,maxX_trn, '-', minY_trn,maxY_trn )"
      ],
      "metadata": {
        "id": "G0g0G0VXI2o7",
        "outputId": "007873e4-b9e4-4d8f-ee51-b36fb01ba5fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 100 - 1 100\n",
            "1 50 - 1 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# last find totam min max \n",
        "min_quadranX = (min(minX_inp,minX_trn))\n",
        "max_quadranX = (max(maxX_inp,maxX_trn))\n",
        "\n",
        "min_quadranY = (max(minY_inp,minY_trn))\n",
        "max_quadranY = (max(maxY_inp,maxY_trn))\n",
        "\n",
        "print(min_quadranX, max_quadranX, '-', min_quadranY, max_quadranY )\n"
      ],
      "metadata": {
        "id": "h3l2p_HmKfL9",
        "outputId": "05ba37c5-d970-464a-c4d1-7d23591f518a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 100 - 1 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the points ( inp -> o , train -> x )"
      ],
      "metadata": {
        "id": "7Hve7t1Qrxc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mx = [val.inpX for val in df_inp.select('inpX').collect()]\n",
        "my = [val.inpY for val in df_inp.select('inpY').collect()]\n",
        "plt.scatter(mx, my, marker='x', color = 'brown')\n",
        "\n",
        "tx = [val.trainX for val in df_train.select('trainX').collect()]\n",
        "ty = [val.trainY for val in df_train.select('trainY').collect()]\n",
        "plt.scatter(tx, ty, marker='p', color = 'blue')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "08TyXRTw8fZM",
        "outputId": "e74f8ad5-805d-4bd0-e87f-58a7bffa8e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the value for distance range from user"
      ],
      "metadata": {
        "id": "LR-xUX4rl910"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "range_val = 0\n",
        "try:\n",
        "  range_val = float(input(\"Enter the value for distance between the points: \"))\n",
        "except ValueError:\n",
        "    print(\"This is not a number\")    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CilfUq7_ltfq",
        "outputId": "06f8cb96-bfb7-48eb-d12d-e0af0e9cc6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the value for distance between the points: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We are going to find the size for the cells that the grid will split"
      ],
      "metadata": {
        "id": "uATC-RVmMiyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_splits = 0\n",
        "try:\n",
        "  total_splits = int(input(\"Enter the value for splits: \"))\n",
        "except ValueError:\n",
        "    print(\"This is not a number\")  "
      ],
      "metadata": {
        "id": "tiUgmi8NNxo2",
        "outputId": "16e0217e-c652-496e-bc4c-7dbf43677647",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the value for splits: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dimension_x = abs((max_quadranX - min_quadranX)) / total_splits\n",
        "dimension_y = abs((max_quadranY - min_quadranY)) / total_splits\n",
        "\n",
        "print(dimension_x, dimension_y)"
      ],
      "metadata": {
        "id": "IraQTzo6NELx",
        "outputId": "31f644b6-2c73-4226-bd49-bd42bd02be29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.475 2.475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Before starting the process we are going to partition both dataframes"
      ],
      "metadata": {
        "id": "hJmv1C9Z1-Oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"*** Looking at partitions *** \")\n",
        "\n",
        "### first for inp dataframe ### \n",
        "inp_partitionCount = df_inp.rdd.getNumPartitions()\n",
        "print(\"Partition count before repartition: {}\".format(inp_partitionCount))\n",
        "df_inp = df_inp.repartition(1)\n",
        "print(\"Partition count for input dataframe after repartition: {}\".format(df_inp.rdd.getNumPartitions()))\n",
        "\n",
        "### same for train dataframe ### \n",
        "train_partitionCount = df_train.rdd.getNumPartitions()\n",
        "print(\"Partition count before repartition: {}\".format(train_partitionCount))\n",
        "df_train = df_train.repartition(1)\n",
        "print(\"Partition count for train dataframe after repartition: {}\".format(df_train.rdd.getNumPartitions()))\n",
        "\n",
        "print(\"end of handling partitions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL778zNX2PyF",
        "outputId": "6cf8e6b4-f270-4e2f-c894-2b5ac3eb614b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Looking at partitions *** \n",
            "Partition count before repartition: 1\n",
            "Partition count for input dataframe after repartition: 1\n",
            "Partition count before repartition: 1\n",
            "Partition count for train dataframe after repartition: 1\n",
            "end of handling partitions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a function that calculates the distance between two points"
      ],
      "metadata": {
        "id": "qsBYt5yO0wpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate distance between points using Pythagoras' theorem\n",
        "import math\n",
        "def distance(i1 , t1 , i2 , t2):\n",
        " \n",
        "    return math.sqrt(math.pow(i2 - i1, 2) + math.pow(t2 - t1, 2) * 1.0)"
      ],
      "metadata": {
        "id": "H-3q6_cq7QJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to call in order to calculate the points of train that are in range of points of input\n",
        "\n",
        "def check_in_range(i, t, r):\n",
        "\n",
        "  for a in range(i.count()) :\n",
        "   for b in range(t.count()) :\n",
        "    print( '(' , i.collect()[a][0] , i.collect()[a][1] , ')', '-', '(' , t.collect()[b][0] , t.collect()[b][1], ')')\n",
        "    dist = distance(i.collect()[a][1] , i.collect()[a][0] , t.collect()[b][1] , t.collect()[b][0])\n",
        "\n",
        "    if dist <= range_val :\n",
        "      print(\"Points in range :\", dist, \"<=\", r)\n",
        "    else : \n",
        "      print(\"Points out of range :\", dist, \">\", r)\n",
        "    \n",
        "    print(\"----------------------\")"
      ],
      "metadata": {
        "id": "IPy2LNOO7VXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now call the functions in order to get the requested results"
      ],
      "metadata": {
        "id": "3GrbqXHI6w2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t4 = int(round(time.time() * 1000))"
      ],
      "metadata": {
        "id": "_czcEZ740VRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_with_range_flag = []\n",
        "check_in_range(df_inp, df_train, range_val)"
      ],
      "metadata": {
        "id": "lL-VlBsG65Uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5 = int(round(time.time() * 1000))\n",
        "print(\"Analyzing result in {} ms\".format(t5 - t4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY6Nqbdz0tU8",
        "outputId": "b3db89cf-2f89-42b1-93a6-31076293396e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing result in 19283 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the previous were just to test that spark was ok set up\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "j0PUG8qNyrXv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}